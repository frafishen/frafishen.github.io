<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  

  
  <title>沈倢妤的空間</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="website">
<meta property="og:title" content="沈倢妤的空間">
<meta property="og:url" content="https://frafishen.github.io/index.html">
<meta property="og:site_name" content="沈倢妤的空間">
<meta property="og:locale" content="zh_TW">
<meta property="article:author" content="Jenny Shen">
<meta name="twitter:card" content="summary">
  
    <link rel="alternate" href="/atom.xml" title="沈倢妤的空間" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  
<link rel="stylesheet" href="/css/style.css">

<meta name="generator" content="Hexo 5.4.2"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">沈倢妤的空間</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="搜尋"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="https://frafishen.github.io"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main">
  
    <article id="post-introduction" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2022/06/23/introduction/" class="article-date">
  <time datetime="2022-06-23T15:11:40.000Z" itemprop="datePublished">2022-06-23</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2022/06/23/introduction/">沈倢妤的簡歷</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <img src="/image/head.jpg" align="left" width="250" />

<h2 id="一、-基本資料"><a href="#一、-基本資料" class="headerlink" title="(一、) 基本資料"></a>(一、) 基本資料</h2><h3 id="1-學校：國立政治大學-預計畢業於2025"><a href="#1-學校：國立政治大學-預計畢業於2025" class="headerlink" title="(1) 學校：國立政治大學 (預計畢業於2025)"></a>(1) 學校：國立政治大學 (預計畢業於2025)</h3><h3 id="2-主修：資訊管理學系"><a href="#2-主修：資訊管理學系" class="headerlink" title="(2) 主修：資訊管理學系"></a>(2) 主修：資訊管理學系</h3><h3 id="3-學程：英語商管學程（ETP）-金融科技專長學程-Fintech-Progrom"><a href="#3-學程：英語商管學程（ETP）-金融科技專長學程-Fintech-Progrom" class="headerlink" title="(3) 學程：英語商管學程（ETP） / 金融科技專長學程(Fintech Progrom)"></a>(3) 學程：英語商管學程（ETP） / 金融科技專長學程(Fintech Progrom)</h3><p>目前英語授課科目為：程式設計、計算機概論、初級會計學、經濟學、資料結構</p>
<br>

<h3 id="4-聯絡資訊："><a href="#4-聯絡資訊：" class="headerlink" title="(4)聯絡資訊："></a>(4)聯絡資訊：</h3><h5 id="信箱-x78-48-x31-56-x30-51-54-x38-57-48-x35-64-103-109-x61-105-108-x2e-x63-x6f-109"><a href="#信箱-x78-48-x31-56-x30-51-54-x38-57-48-x35-64-103-109-x61-105-108-x2e-x63-x6f-109" class="headerlink" title="信箱: &#x78;&#48;&#x31;&#56;&#x30;&#51;&#54;&#x38;&#57;&#48;&#x35;&#64;&#103;&#109;&#x61;&#105;&#108;&#x2e;&#x63;&#x6f;&#109;"></a>信箱: <a href="mailto:&#x78;&#48;&#x31;&#56;&#x30;&#51;&#54;&#x38;&#57;&#48;&#x35;&#64;&#103;&#109;&#x61;&#105;&#108;&#x2e;&#x63;&#x6f;&#109;">&#x78;&#48;&#x31;&#56;&#x30;&#51;&#54;&#x38;&#57;&#48;&#x35;&#64;&#103;&#109;&#x61;&#105;&#108;&#x2e;&#x63;&#x6f;&#109;</a></h5><h5 id="Linkedin-https-www-linkedin-com-in-shen-jie-yu"><a href="#Linkedin-https-www-linkedin-com-in-shen-jie-yu" class="headerlink" title="Linkedin: https://www.linkedin.com/in/shen-jie-yu/"></a>Linkedin: <a target="_blank" rel="noopener" href="https://www.linkedin.com/in/shen-jie-yu/">https://www.linkedin.com/in/shen-jie-yu/</a></h5><h5 id="github-https-github-com-frafishen"><a href="#github-https-github-com-frafishen" class="headerlink" title="github: https://github.com/frafishen"></a>github: <a target="_blank" rel="noopener" href="https://github.com/frafishen">https://github.com/frafishen</a></h5></br>

<h2 id="二、-硬實力"><a href="#二、-硬實力" class="headerlink" title="(二、) 硬實力"></a>(二、) 硬實力</h2><h3 id="1-專案經驗："><a href="#1-專案經驗：" class="headerlink" title="(1) 專案經驗："></a>(1) 專案經驗：</h3><h4 id="瘋狂做菜-Java-Python-gt-Android-App"><a href="#瘋狂做菜-Java-Python-gt-Android-App" class="headerlink" title="*瘋狂做菜(Java + Python -&gt; Android App)"></a>*瘋狂做菜(Java + Python -&gt; Android App)</h4><p><a target="_blank" rel="noopener" href="https://github.com/frafishen/CO2K">github 連結</a> / <a target="_blank" rel="noopener" href="https://mail3nccu-my.sharepoint.com/:p:/g/personal/110306010_mail3_nccu_tw/EfMs8nkX3hhHvsWaKQeNDCcBaY6bJFfszfaZ5YMqBQoUlw?e=G5DurB">簡報，密碼1234</a><br>團隊作品，我為主要寫程式的成員，負責系統介面及功能整合。</p>
<h4 id="選課小精靈-Java-application"><a href="#選課小精靈-Java-application" class="headerlink" title="*選課小精靈(Java application)"></a>*選課小精靈(Java application)</h4><p><a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=auSfF2Il12c">專案介紹影片</a> / <a target="_blank" rel="noopener" href="https://reurl.cc/d2kWe2">系統操作手冊</a> / <a target="_blank" rel="noopener" href="https://reurl.cc/b28EQr">jar 檔下載</a><br>團隊作品，但我為主要寫程式的成員。</p>
<h4 id="選課小精靈-Web1-0-Vue3-Web-Page"><a href="#選課小精靈-Web1-0-Vue3-Web-Page" class="headerlink" title="*選課小精靈-Web1.0(Vue3 Web Page)"></a>*選課小精靈-Web1.0(Vue3 Web Page)</h4><p><a href="https://frafishen.github.io/NCCU-Mocking-Schedule/">選課小精靈主頁</a><br>個人作品，將選課小精靈(Java)中，模擬課表的部分單獨拉出來做了一個以Vue3為框架的網頁。</p>
<h3 id="2-程式解題能力-Java-C-："><a href="#2-程式解題能力-Java-C-：" class="headerlink" title="(2) 程式解題能力(Java/C++)："></a>(2) 程式解題能力(Java/C++)：</h3><p><a target="_blank" rel="noopener" href="https://leetcode.com/x0180368905/">leetcode</a></p>
<h3 id="3-外文證照："><a href="#3-外文證照：" class="headerlink" title="(3) 外文證照："></a>(3) 外文證照：</h3><p>*GEPT (全民英檢) 中高級：B2+<br></br></p>
<h2 id="三、-特別經歷："><a href="#三、-特別經歷：" class="headerlink" title="(三、) 特別經歷："></a>(三、) 特別經歷：</h2><h3 id="1-全國佳作-4th-2021第二屆三星Solve-for-Tomorrow-「新思維，心技術，共創星未來」創意提案競賽"><a href="#1-全國佳作-4th-2021第二屆三星Solve-for-Tomorrow-「新思維，心技術，共創星未來」創意提案競賽" class="headerlink" title="(1) 全國佳作(4th)2021第二屆三星Solve for Tomorrow 「新思維，心技術，共創星未來」創意提案競賽"></a>(1) 全國佳作(4th)<a target="_blank" rel="noopener" href="https://contest.bhuntr.com/tw/2021-samsung-solve-for-tomorrow/home/#homepage">2021第二屆三星Solve for Tomorrow 「新思維，心技術，共創星未來」創意提案競賽</a></h3><p>團隊名稱：L.W.E.T (Leaning With Everyone Team)</br><br>作品名稱：ZBridge (Z世代的智慧橋梁)</br><br><a target="_blank" rel="noopener" href="https://reurl.cc/7DvGm1">海報 </a><a target="_blank" rel="noopener" href="https://reurl.cc/Kbn75p">簡報</a></p>
<h3 id="2-全國佳作-4th-2022全國大專院校智慧創新既跨域整合創作競賽-金融科技與電商組"><a href="#2-全國佳作-4th-2022全國大專院校智慧創新既跨域整合創作競賽-金融科技與電商組" class="headerlink" title="(2) 全國佳作(4th) 2022全國大專院校智慧創新既跨域整合創作競賽 金融科技與電商組"></a>(2) 全國佳作(4th) <a target="_blank" rel="noopener" href="https://niicc.cilab.csie.ncu.edu.tw/achievement/achieveresult/40249">2022全國大專院校智慧創新既跨域整合創作競賽 金融科技與電商組</a></h3><p>團隊名稱：二進位</br><br>作品名稱：瘋狂做菜！</br><br><a target="_blank" rel="noopener" href="https://github.com/frafishen/CO2K">github 連結</a></p>
<h3 id="3-111-學年度國立政治大學資管系系學會會長"><a href="#3-111-學年度國立政治大學資管系系學會會長" class="headerlink" title="(3) 111 學年度國立政治大學資管系系學會會長"></a>(3) 111 學年度國立政治大學資管系系學會會長</h3><p>有祕書部、總務部、公關部、宣傳部、活動部(專案組、體育組)、學術部<br>包含正副會長共九名核心幹部<br>成員：19名大二，22名大一</p>
<h3 id="4-經營-Youtube-頻道：嗨大家-我是香魚"><a href="#4-經營-Youtube-頻道：嗨大家-我是香魚" class="headerlink" title="(4) 經營 Youtube 頻道：嗨大家 我是香魚"></a>(4) 經營 Youtube 頻道：<a target="_blank" rel="noopener" href="https://www.youtube.com/channel/UCAX3EGYxsWJdcHl12F47GEw">嗨大家 我是香魚</a></h3><p>這個頻道主要會放一些，當時我很有興趣的議題，研究完之後分享給大家。</p>
<h3 id="5-其他團隊合作經歷："><a href="#5-其他團隊合作經歷：" class="headerlink" title="(5) 其他團隊合作經歷："></a>(5) 其他團隊合作經歷：</h3><p>政大包種茶節 2021：資管系課程組</br><br>Aiesec 2022 iContact 營隊承辦(課程組)</br><br>政大資管營 2022：課程組組長</br><br>ATCC 2022 全國大專院校商業個案大賽參賽</br></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://frafishen.github.io/2022/06/23/introduction/" data-id="cl50peruw0003toc226iz0qmb" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/about/" rel="tag">about</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-20th-birthday" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2022/10/18/20th-birthday/" class="article-date">
  <time datetime="2022-10-18T10:38:54.000Z" itemprop="datePublished">2022-10-18</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2022/10/18/20th-birthday/">20 Year Old Birthday</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="我二十歲了，是個大人了。"><a href="#我二十歲了，是個大人了。" class="headerlink" title="我二十歲了，是個大人了。"></a>我二十歲了，是個大人了。</h2><p>過去的一年，我在政大過著我在高中從來沒有想過的人生。<br>總覺得過去的一年我經歷了好多，想要藉由這篇文章回顧一下。</p>
<p>十九歲的回顧：(只提課外活動的部分)</p>
<ul>
<li><strong>2021/10/18</strong> 我的十九歲生日，同時也是我上大學之後的第一個生日。</li>
<li>這個時候的我，很閒，很想找事做，所以有三個家教在身上。</li>
<li>加入了Aiesec NCCU，這個社團裡，充滿了許多對自己的也很迷惘了人，我在這裡交到了我上大學之後的第一個不同系的朋友。</li>
<li>想要藉由運動認識其他同學，所以加入了系桌。</li>
<li>升大學的暑假，我參加了Samsung的第二屆創意提案競賽(Solve for Tomorrow)，當時正在進行複賽。總覺得人生需要一點挑戰性，看到信箱裡有聯合利華的提案競賽的報名表，就找了在Aiesec認識的新朋友，和一個從高中之後就沒有同班過的國中同學一起參加。結果後來因為撞到期中考，我們不約而同地選擇忘記這次的衝動報名。我有點對不起我的那位國中同學。</li>
<li><strong>2021/10/29</strong> Samsung Solve for Tomorrow(SFT) 晉級全國決賽。找了010和J41老師，聽聽我們的提案。這是我第一次用除了課業之外的名義寄信給老師。</li>
<li>大學第一次期中考，這個時候的我很狂妄，覺得課業很簡單，所以準備考試的同時，接了當時的第四個家教。大腦與我(一門核通)因為只考了45分，所以我申請了棄修。</li>
<li>SFT晉級之後，我跟團隊開始一周至少開會六次的狀態，想盡辦法把提案變得更好。</li>
<li>這個時候的我，很享受在忙碌的生活中，總是喜歡參加各種演講，或是奇奇怪怪的活動，把自己的時間表填滿。</li>
<li><strong>2021/11/3</strong> 參加系上舉辦的混保活動，第一次參加系上的康輔活動。</li>
<li><strong>2021/12/10</strong> 在SFT的全國決賽中，我跟團隊獲得了全國佳作(第四名的成績)。這是我第一次獲得全國性的比賽殊榮。我的心態變得更加膨脹了。</li>
<li>我接了當時的第五個家教，月薪記得有破三萬。我當時真的瘋了，接這麼多家教幹嘛。</li>
<li><strong>2021/12/17</strong> 和男朋友參加了耶誕舞會，我再也不會去夜店類型的地方。</li>
<li><strong>2022/1/14~15</strong> 和大一認識的新朋友參加宿營。</li>
<li><strong>2022/1/18~19</strong> 想要成為商院elite，所以參加了商院菁英種子營。聽了兩天的演講。</li>
<li><strong>2022/1/28</strong> 我終於考過全民英檢中高級了。</li>
<li><strong>2022/2/6~7</strong> 和系桌一起參加大資杯，第一次因為跑行程把自己的身體跑壞掉。當然，比賽也爛掉。</li>
<li>SFT得到全國第四的我，覺得自己很厲害，很會比賽，所以參與了2022 ATCC，想證明自己不是靠運氣，結果第二輪就被刷掉了。想要參加金融研習社，結果連面試都沒有過，但我之後有參與旁聽課程。</li>
<li>聽說商院生涯大使(CCA)很厲害，學生大使被刷掉的我，又在嘗試了一次，又被刷掉，我再也不參加大使系列的活動了。不適合我。</li>
<li>多次的失敗再加上期中考也不是考得很好，使我開始反省自己到底想要什麼，我將家教退到剩下三個。</li>
<li>接下來的大一下學期，不知道是在沉澱，還是我突然發現需要念書了，什麼活動都沒有參加了。</li>
<li>上大學之後的第一個暑假開始了，開始覺得很空虛，所以參加了夏季學院和ewant，準備上兩門通識課。然後將程式設計二的final project用Vue3的前端框架再寫了一次。學到了很多網頁相關的技巧。</li>
<li><strong>2022/6/29</strong> 我又嘗試參加比賽了。這次是與系上同學一起參與了2022全國大專院校智慧創新暨跨域整合創作競賽。參加的是金融科技與電商組。</li>
<li> 暑假還參與了一門未來巢所舉辦的資料科學課程，學了資料清洗、資料處理、機器學習，用python實作，並最後以區塊鏈防洗錢專案收尾。團隊得到了整個課程中的第一名。</li>
<li> <strong>2022/7/15</strong> 得知自己會是111屆的政大資管系學會會長。之後慢慢經營，大二有19個，大一有22個同學加入系學會。</li>
<li> 雖然很忙，但是覺得自己開學會很閒，而且又沒有申請雙輔，所以就開始丟實習。最後有拿到5份offer。包含金融業、科技業、資策會。</li>
<li> 因為家裡不讓我在這個年紀實習，所以跑去跟010爭取在他身邊做專案，後續有找了3個朋友一起接了一個跟企管系信義書院合作的專案，與text mining和CSR有關。</li>
<li> 開學之後，我要以會長的身分參與許多活動，我的氣場跟臺風變得很強勢。</li>
<li> 接了包種茶的資管系公關組組長，我底下有22個大一，真的好多。</li>
<li> 因為要做CSR專案的關係，所以我跟團隊已起去旁聽010的文字探勘課程。這門課是學碩混開，不開放低年級選修。好硬，但好爽。</li>
<li> <strong>2022/9/12</strong> 全國大專院校智慧創新暨跨域整合創作競賽(aka智創賽)晉級全國決賽，真的要將app寫出來了。</li>
<li> <strong>2022/10/6</strong> 啤酒節被炎上了，我的系學會第一次遇到直接炸掉的公關事件。後來有處理好。</li>
<li> <strong>2022/10/7</strong> 覺得自己比賽參加完之後會很閒，所以在010那邊又接了一個和斯語系合作的系統專案。</li>
<li> 我在路上被搭訕，被以為是韓國人，然後加入一個奇怪的團體，裡面有美國人、挪威人、澳洲人、法國人，每周我們都會約在路易莎聊天，用英文。</li>
</ul>
<p>以上是我的19歲，雖然還是有點迷惘，生活過得有點離奇，但總的來說，很充實。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://frafishen.github.io/2022/10/18/20th-birthday/" data-id="cl9fk9q46000058c22haq5tqh" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/about/" rel="tag">about</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-build-vir-env" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2023/02/18/build-vir-env/" class="article-date">
  <time datetime="2023-02-18T03:49:04.000Z" itemprop="datePublished">2023-02-18</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/02/18/build-vir-env/">Build a Virtual Environment for Development Purpose</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="Step-1-安裝virtualenv"><a href="#Step-1-安裝virtualenv" class="headerlink" title="Step 1: 安裝virtualenv"></a>Step 1: 安裝virtualenv</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip3 install virtualenv</span><br></pre></td></tr></table></figure>
<h2 id="Step-2：建立虛擬環境"><a href="#Step-2：建立虛擬環境" class="headerlink" title="Step 2：建立虛擬環境"></a>Step 2：建立虛擬環境</h2><p>下面virtualenv是虛擬機的指令，env01是虛擬環境的名字。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">virtualenv env01</span><br></pre></td></tr></table></figure>
<p>如果想要建立的是有特殊版本的python環境</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">virtualenv -p python3.8 env01</span><br></pre></td></tr></table></figure>
<h2 id="Step-3：虛擬環境中啟動及安裝所需套件"><a href="#Step-3：虛擬環境中啟動及安裝所需套件" class="headerlink" title="Step 3：虛擬環境中啟動及安裝所需套件"></a>Step 3：虛擬環境中啟動及安裝所需套件</h2><p>啟動，之後可以就在裡面，安裝獨立的環境。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">activate</span><br></pre></td></tr></table></figure>
<h2 id="Step-4：離開虛擬環境"><a href="#Step-4：離開虛擬環境" class="headerlink" title="Step 4：離開虛擬環境"></a>Step 4：離開虛擬環境</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">deactivate</span><br></pre></td></tr></table></figure>
<h2 id="Step-5-在vscode中讓ipynb使用虛擬環境"><a href="#Step-5-在vscode中讓ipynb使用虛擬環境" class="headerlink" title="Step 5: 在vscode中讓ipynb使用虛擬環境"></a>Step 5: 在vscode中讓ipynb使用虛擬環境</h2><p>按下右邊的python版本，那邊可以選擇不同的kernel<br><img src="https://i.imgur.com/Y7rUmRD.png"></p>
<h2 id="Step-6-建立需要的開發環境"><a href="#Step-6-建立需要的開發環境" class="headerlink" title="Step 6: 建立需要的開發環境"></a>Step 6: 建立需要的開發環境</h2><p>假如說想要一次安裝很多package的話，可以開一個requirements.txt，然後將需求像下面這樣填進去</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">numpy&lt;=1.19.2</span><br><span class="line">scipy==1.4.1</span><br><span class="line">pandas==1.1.5</span><br><span class="line">matplotlib==3.2.2</span><br><span class="line">seaborn==0.11.2</span><br><span class="line">scikit-learn==0.24.2</span><br><span class="line">keras==2.6.0</span><br><span class="line">pydot==1.4.2</span><br><span class="line">opencv-python==4.1.2.30</span><br><span class="line">pillow==7.1.2</span><br><span class="line">jupyterlab==3.2.0</span><br><span class="line">torch</span><br><span class="line">tqdm</span><br></pre></td></tr></table></figure>
<p>然後再執行</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install -r requirements.txt</span><br></pre></td></tr></table></figure>
<p>就會全部裝好啦</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://frafishen.github.io/2023/02/18/build-vir-env/" data-id="cle9hzhqr000094c209sf2ttf" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/virtualenv/" rel="tag">virtualenv</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-DLHLP" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2023/02/08/DLHLP/" class="article-date">
  <time datetime="2023-02-08T12:24:11.000Z" itemprop="datePublished">2023-02-08</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/02/08/DLHLP/">DLHLP-2020</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>以下是李弘毅老師在<a target="_blank" rel="noopener" href="https://speech.ee.ntu.edu.tw/~hylee/dlhlp/2020-spring.php">2020開的DLHLP課程</a>部分內容。</p>
<h3 id="DLHLP-2020-Overview-of-NLP-Tasks"><a href="#DLHLP-2020-Overview-of-NLP-Tasks" class="headerlink" title="[DLHLP 2020] Overview of NLP Tasks"></a><a href="https://frafishen.github.io/2023/02/01/DLHLP-2020-1/">[DLHLP 2020] Overview of NLP Tasks</a></h3><h3 id="DLHLP-2020-BERT-and-its-family-Introduction-and-Fine-tune"><a href="#DLHLP-2020-BERT-and-its-family-Introduction-and-Fine-tune" class="headerlink" title="[DLHLP 2020] BERT and its family - Introduction and Fine-tune"></a><a href="https://frafishen.github.io/2023/02/02/DLHLP-2020-2/">[DLHLP 2020] BERT and its family - Introduction and Fine-tune</a></h3><h3 id="DLHLP-2020-BERT-and-its-family-ELMo-BERT-GPT-XLNet-MASS-BART-UniLM-ELECTRA-and-more"><a href="#DLHLP-2020-BERT-and-its-family-ELMo-BERT-GPT-XLNet-MASS-BART-UniLM-ELECTRA-and-more" class="headerlink" title="[DLHLP 2020] BERT and its family - ELMo, BERT, GPT, XLNet, MASS, BART, UniLM, ELECTRA, and more"></a><a href="https://frafishen.github.io/2023/02/05/DLHLP-2020-3/">[DLHLP 2020] BERT and its family - ELMo, BERT, GPT, XLNet, MASS, BART, UniLM, ELECTRA, and more</a></h3><h3 id="DLHLP-2020-Deep-Learning-for-Coreference-Resolution"><a href="#DLHLP-2020-Deep-Learning-for-Coreference-Resolution" class="headerlink" title="[DLHLP 2020] Deep Learning for Coreference Resolution"></a><a href="https://frafishen.github.io/2023/02/06/DLHLP-2020-4/">[DLHLP 2020] Deep Learning for Coreference Resolution</a></h3><h3 id="DLHLP-2020-Deep-Learning-for-Question-Answering"><a href="#DLHLP-2020-Deep-Learning-for-Question-Answering" class="headerlink" title="[DLHLP 2020] Deep Learning for Question Answering"></a><a href="https://frafishen.github.io/2023/02/07/DLHLP-2020-5/">[DLHLP 2020] Deep Learning for Question Answering</a></h3>
      
    </div>
    <footer class="article-footer">
      <a data-url="https://frafishen.github.io/2023/02/08/DLHLP/" data-id="cldvncgwo00007oc2bbs0bpxu" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/DLHLP/" rel="tag">DLHLP</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Hung-yi-Lee/" rel="tag">Hung-yi Lee</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/NLP/" rel="tag">NLP</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/deep-learning/" rel="tag">deep learning</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/python/" rel="tag">python</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-DLHLP-2020-5" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2023/02/07/DLHLP-2020-5/" class="article-date">
  <time datetime="2023-02-07T12:15:32.000Z" itemprop="datePublished">2023-02-07</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/02/07/DLHLP-2020-5/">DLHLP 2020 (5)</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>繼續記錄李宏毅老師的課。<br><a href="https://frafishen.github.io/2023/02/06/DLHLP-2020-4/">上一篇</a></p>
<h2 id="DLHLP-2020-Deep-Learning-for-Question-Answering-1-2-重新上傳"><a href="#DLHLP-2020-Deep-Learning-for-Question-Answering-1-2-重新上傳" class="headerlink" title="[DLHLP 2020] Deep Learning for Question Answering (1/2) (重新上傳)"></a><a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=gRfTfXCe3LA">[DLHLP 2020] Deep Learning for Question Answering (1/2) (重新上傳)</a></h2><h2 id="DLHLP-2020-Deep-Learning-for-Question-Answering-2-2"><a href="#DLHLP-2020-Deep-Learning-for-Question-Answering-2-2" class="headerlink" title="[DLHLP 2020] Deep Learning for Question Answering (2/2)"></a><a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=h_Lptoq8spQ">[DLHLP 2020] Deep Learning for Question Answering (2/2)</a></h2><ul>
<li>語言模型處理QA問題，以困難度分類:<ul>
<li>simple question -&gt; match &amp; extract</li>
<li>complex question -&gt; reasoning</li>
<li>dialogue QA</li>
</ul>
</li>
<li>simple questions<ul>
<li>有很多雜七雜八的作法，詳情可以參閱<a target="_blank" rel="noopener" href="https://mail3nccu-my.sharepoint.com/:b:/g/personal/110306010_mail3_nccu_tw/EcT2yVHxdh5Og-pFdvgFpKEB--rfWfJoGCsVQRnKCIQskw?e=Cj0iZ1">簡報</a>中的舉例</li>
<li>在Bert中，就是用start and end去實踐 -&gt; sQuAD<br><img src="https://i.imgur.com/11yC5gG.png"></li>
</ul>
</li>
<li>complex question<ul>
<li>需要區推論一些簡單的問題。比如說文章中只有提到March 3rd, next day，那model就應該要自動可以辨別出，應該要輸出March 4th，所以在單純extract的情況下，這樣的回答就一定會壞掉。</li>
<li>可以使用的方法:<ul>
<li>multiple-hop，多hop幾次有可能就會出來，但是這也還是extract，只是可以跨sequence<br><img src="https://i.imgur.com/Pulzs1D.png"></li>
<li>memory network<br><img src="https://i.imgur.com/ZcJqa7b.png"></li>
<li>graph neural network<br><img src="https://i.imgur.com/sRZP9tS.png"></li>
</ul>
</li>
</ul>
</li>
<li>dialogue QA<br><img src="https://i.imgur.com/38meP1M.png"></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://frafishen.github.io/2023/02/07/DLHLP-2020-5/" data-id="cldvncgwv00027oc25fh62wv4" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/DLHLP/" rel="tag">DLHLP</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Hung-yi-Lee/" rel="tag">Hung-yi Lee</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/NLP/" rel="tag">NLP</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/deep-learning/" rel="tag">deep learning</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/python/" rel="tag">python</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-DLHLP-2020-4" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2023/02/06/DLHLP-2020-4/" class="article-date">
  <time datetime="2023-02-05T17:40:49.000Z" itemprop="datePublished">2023-02-06</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/02/06/DLHLP-2020-4/">DLHLP 2020 (4)</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>繼續記錄李宏毅老師的課。<br><a href="https://frafishen.github.io/2023/02/05/DLHLP-2020-3/">上一篇</a><br><a href="https://frafishen.github.io/2023/02/07/DLHLP-2020-5/">下一篇</a></p>
<h2 id="DLHLP-2020-Deep-Learning-for-Coreference-Resolution"><a href="#DLHLP-2020-Deep-Learning-for-Coreference-Resolution" class="headerlink" title="[DLHLP 2020] Deep Learning for Coreference Resolution"></a><a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=2BemmceHKOU">[DLHLP 2020] Deep Learning for Coreference Resolution</a></h2><ul>
<li>coreference resolution簡單來說就是將敘述中，代表同樣entity的token弄成一個集放在一起。</li>
<li>比較原始的做法原則上就是會需要先製造一個binary classifier，去判斷新輸入的這個token是不是和已經有的cluster們歸類在一起。時間複雜度差不多是O(n^4)，n表示的token的數量。當中的平方代表的是倆倆需要配對，另外的平方是因為需要比對兩兩配對過的，是不是表示同一個意思。</li>
<li>假如說要做一個完全end2end的biinary classification model，就是直接忽略掉mention ranking model<br><img src="https://i.imgur.com/mTB8bT2.png"></li>
<li>其實上述這樣的架構也是會有一些問題。比如說{Mr. Lee, Lee, She}，這的cluster其實是有機率出現的，因為model可能會覺得說Mr. Lee和Lee是同一個，但是其實後面的She也確實是姓Lee，但是顯然這三個不是同一群。有一種解決辦法是利用，unsupervised的方式訓練一個[MASK]，來讓model直接猜，被遮掉的屬於什麼，自動cluster。</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://frafishen.github.io/2023/02/06/DLHLP-2020-4/" data-id="cldv1dcyk00008sc2dar458iv" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/DLHLP/" rel="tag">DLHLP</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Hung-yi-Lee/" rel="tag">Hung-yi Lee</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/NLP/" rel="tag">NLP</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/deep-learning/" rel="tag">deep learning</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/python/" rel="tag">python</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-DLHLP-2020-3" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2023/02/05/DLHLP-2020-3/" class="article-date">
  <time datetime="2023-02-04T17:36:21.000Z" itemprop="datePublished">2023-02-05</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/02/05/DLHLP-2020-3/">DLHLP 2020 (3)</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>繼續記錄李宏毅老師的課。<br><a href="https://frafishen.github.io/2023/02/02/DLHLP-2020-2/">上一篇</a><br><a href="https://frafishen.github.io/2023/02/06/DLHLP-2020-4/">下一篇</a></p>
<h2 id="DLHLP-2020-BERT-and-its-family-ELMo-BERT-GPT-XLNet-MASS-BART-UniLM-ELECTRA-and-more"><a href="#DLHLP-2020-BERT-and-its-family-ELMo-BERT-GPT-XLNet-MASS-BART-UniLM-ELECTRA-and-more" class="headerlink" title="[DLHLP 2020] BERT and its family - ELMo, BERT, GPT, XLNet, MASS, BART, UniLM, ELECTRA, and more"></a><a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=Bywo7m6ySlk">[DLHLP 2020] BERT and its family - ELMo, BERT, GPT, XLNet, MASS, BART, UniLM, ELECTRA, and more</a></h2><h2 id="Contextualized-Word-Embedding"><a href="#Contextualized-Word-Embedding" class="headerlink" title="Contextualized Word Embedding"></a>Contextualized Word Embedding</h2><ul>
<li>原本的 word embedding 基本上就是每個word會有一個自己的向量，也就是每個type(字)只會有個token(意思-&gt;向量)</li>
<li>Contextualized 的技術就是讓同一個type，在句子中，會根據前後的type的token去判斷，應該自己是哪個token</li>
</ul>
<h2 id="ELMO"><a href="#ELMO" class="headerlink" title="ELMO"></a>ELMO</h2><ul>
<li>ELMO 是基於 RNN 的模型<ul>
<li>只需要收集一堆的句子，不需要特別去進行標籤</li>
<li>訓練的點：下一個會出現的token是什麼</li>
<li>正反都做一次，就能分析上下文了</li>
<li>因為deep learning，所以會有很多層，所以分析出來，可能也會有很多個token的結果。ELMO的做法就是對每一層有一個參數(相對於超參數，是動態的，因為對於不同的問題，不同層的結果重要程度可能會不同)，對每一層加權，共同決定最後預測的token</li>
</ul>
</li>
</ul>
<h2 id="BERT"><a href="#BERT" class="headerlink" title="BERT"></a>BERT</h2><ul>
<li>encoder of transformer 就是bert的network架構</li>
<li>一般如果要transform一個transformer的話，就需要有一些東西pass過去，像是 translation, summerization之類的，但bert的邏輯，就是直接去transform transformer的encoder就可以了，所以不需要上label，直接丟句子進去就可以了</li>
<li>運作邏輯就是給一串sequence，bert就會吐一串embedding的sequence出來</li>
<li>中文如果利用bert的話，顆粒度用字等級的，會更為恰當，因為用詞做embedding的話，計算的維度會太大</li>
<li><h3 id="BERT怎麼訓練的"><a href="#BERT怎麼訓練的" class="headerlink" title="BERT怎麼訓練的?"></a>BERT怎麼訓練的?</h3><h4 id="Masked-LM"><a href="#Masked-LM" class="headerlink" title="Masked LM"></a>Masked LM</h4></li>
<li>隨機蓋掉裡面15%的字詞，用[MASK]代替，用克漏字的方式去訓練模型。</li>
<li>每個被[MASK]的地方，就會產生embedding的vector，那這個vector再丟進一個Linear Multi-class classifier，去預測被[MASK]掉的是哪個詞彙。</li>
<li>如果兩個詞彙填在同一個地方沒有違和感，那就代表他們語意差不多，也就表示出來的embedding會很相近<h4 id="Next-sentence-prediction"><a href="#Next-sentence-prediction" class="headerlink" title="Next sentence prediction"></a>Next sentence prediction</h4></li>
<li>在兩個句子中間插入一個特殊的token，[SEP]，表示兩個句子的交界</li>
<li>還有一個特殊的token，[CLS]，表示從這裡開始去做classification<ul>
<li>從這裡出來的embedding，丟進Linear binary classifier(輸出yes or no)，要判斷的就是，這句話跟其他句話是不是應該要接在一起的。(屬不屬於上下文句子?)</li>
</ul>
</li>
<li>bert的內部不是RNN，是一個transformer <ul>
<li>內部是self attention，不考慮positional encoding的情況，token放在句首還是尾其實沒有區別</li>
<li>self attention跟雙向RNN有同樣能力，可以先偷看過整個sequence，但特別的是輸入的type是同時處理計算token的，不需要一個算完才能算下一個</li>
<li>以前用RNN發表過的paper已經全部被使用self-attention機制洗一輪了… by李宏毅教授</li>
</ul>
</li>
</ul>
<h4 id="“Masked-LM”-amp-“Next-sentence-prediction”-一起用，效果最好"><a href="#“Masked-LM”-amp-“Next-sentence-prediction”-一起用，效果最好" class="headerlink" title="“Masked LM” &amp; “Next sentence prediction” 一起用，效果最好"></a>“Masked LM” &amp; “Next sentence prediction” 一起用，效果最好</h4><h3 id="BERT怎麼用"><a href="#BERT怎麼用" class="headerlink" title="BERT怎麼用?"></a>BERT怎麼用?</h3><h4 id="Case-1"><a href="#Case-1" class="headerlink" title="Case 1"></a>Case 1</h4><ul>
<li>輸入一堆句子，輸出文章類別<ul>
<li>在輸入的最前面加入[CLS]</li>
<li>將輸出的embedding再丟入Linear Classifier (train from scratch)</li>
<li>然後就能預測丟入的句子1, 句子2, 句子3…屬於什麼類型(class)的文章</li>
<li>應用：情緒分析、文本分類<h4 id="Case-2"><a href="#Case-2" class="headerlink" title="Case 2"></a>Case 2</h4></li>
</ul>
</li>
<li>輸入單一句子，輸出每個字詞的類別<ul>
<li> 在輸入的最前面加入[CLS]</li>
<li> 將輸出的embedding再丟入Linear Classifier (每個字詞都會有embedding)</li>
<li> 應用：slot filling<h4 id="Case-3"><a href="#Case-3" class="headerlink" title="Case 3"></a>Case 3</h4></li>
</ul>
</li>
<li>輸入兩個句子，輸出判斷類別(成立/不成立/不知道)<ul>
<li>輸入：[CLS]sen1[SEP]sen2</li>
<li>應用：Natural Language Inference　-&gt; 根據前提，這個假設成不成立，或是不知道<h4 id="Case-4"><a href="#Case-4" class="headerlink" title="Case 4"></a>Case 4</h4></li>
</ul>
</li>
<li>輸入一篇文章，跟問題，答案如果有出現在文章裡面，就能夠輸出答案<ul>
<li>輸入：[CLS]question sequnce[SEP]document</li>
<li>輸出：答案在document中的哪裏到哪裡</li>
<li>文章裡的每個字詞都有embedding</li>
<li>應用：Extraction-based Question Answering(QA), (eg, SQuAD)</li>
</ul>
</li>
</ul>
<h3 id="ERNIE"><a href="#ERNIE" class="headerlink" title="ERNIE"></a>ERNIE</h3><ul>
<li>design for 中文的 BERT</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://frafishen.github.io/2023/02/05/DLHLP-2020-3/" data-id="clduizhhy00007kc2afgt47pd" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/DLHLP/" rel="tag">DLHLP</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Hung-yi-Lee/" rel="tag">Hung-yi Lee</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/NLP/" rel="tag">NLP</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/deep-learning/" rel="tag">deep learning</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/python/" rel="tag">python</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-DLHLP-2020-2" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2023/02/02/DLHLP-2020-2/" class="article-date">
  <time datetime="2023-02-02T10:50:05.000Z" itemprop="datePublished">2023-02-02</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/02/02/DLHLP-2020-2/">DLHLP 2020 (2)</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>繼續記錄李宏毅老師的課。<br><a href="https://frafishen.github.io/2023/02/01/DLHLP-2020-1/">上一篇</a><br><a href="https://frafishen.github.io/2023/02/05/DLHLP-2020-3/">下一篇</a></p>
<h2 id="DLHLP-2020-BERT-and-its-family-Introduction-and-Fine-tune"><a href="#DLHLP-2020-BERT-and-its-family-Introduction-and-Fine-tune" class="headerlink" title="[DLHLP 2020] BERT and its family - Introduction and Fine-tune"></a><a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=1_gRK9EIQpc">[DLHLP 2020] BERT and its family - Introduction and Fine-tune</a></h2><p><img src="https://i.imgur.com/qb7Frxi.png"></p>
<ul>
<li>一般的embedding就是只要token長的是一樣的，那embedding就會是一樣的。Contextualized word embedding則是會根據token的上下文，分別給token各自的embedding，所以就算都是”狗”，”小狗”和”單身狗”的”狗”的embedding也會不一樣。</li>
<li>跟Bert相比，還有一些比較輕量的模型，邏輯上就是將有些原本需要學習的中間參數，直接寫死在模型裡面，但實驗結果發現其實結果沒有差很多。<ul>
<li>Distill BERT</li>
<li>Tiny BERT</li>
<li>Mobile BERT</li>
<li>Q8BERT</li>
<li>ALBERT -&gt; 這個最常見到</li>
</ul>
</li>
<li>除此之外，有有一些架構是將過程的self-attention的複雜度降低<ul>
<li>reformer</li>
<li>longformer</li>
</ul>
</li>
<li>tranformer-XL: 在將架構延長的情況下，Level Recurrence with State Reuse</li>
<li>假如說output是源自於input的某一個段落，根據<a href="https://frafishen.github.io/2023/02/01/DLHLP-2020-1/">上一篇</a>，會需要在document中，尋找start跟end的位置。<ul>
<li><img src="https://i.imgur.com/JLPgSlC.png"></li>
<li>sequence進到model之後，會產生一串對應到每個token的embedding，不同的specific task like find start or find end，就會有一個task specific vector，然後這些vector會去跟embedding做dot product，然後取softmax值(將內積出來的東西映射到0到1的區間)，最後取最大的值，說他就是start或是end。</li>
<li>以上都是利用copy的方式，直接從輸入取材料到輸出。假如說想要輸出一個比較general的sequence，那就需要encoder和decoder。<ul>
<li>encoder: 原本model會將輸入的token轉亂為embedding，這個就是encoder了</li>
<li>decoder: task specific model就會是decoder，通常label data不多，所以會希望可以希望整個model可以先經過pre-train。做法可以將model輸出的embedding丟進task specific model之後，在丟回輸入，然後在進去model，周而復始。這樣就可以迴避掉decoder都沒有pre-train到的問題，利用encoder就可以了。</li>
</ul>
</li>
<li>前面是因為可能沒有太多task specific的資料，所以沒有去fine-tune到decoder。假如說其實資料量夠，那將整個model都fine-tune，表現會更好，但相對的，每個task specific model都要存起來，就會很花記憶體，所以就有一種機制，是指將會不一樣的參數存起來，稱為adaptor，剩下的就共用一個model。</li>
<li>在訓練model的過程中，會有一堆的layer，每一層可能會抽取不同的資訊去做訓練，可以將這些階段性的embedding去做weighted，然後加起來，在拿去task specific model裡面。其中，這個weighted的係數w們，都是可以用學習來的參數。</li>
</ul>
</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://frafishen.github.io/2023/02/02/DLHLP-2020-2/" data-id="clduhktws00004kc2cuwd3pe2" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/DLHLP/" rel="tag">DLHLP</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Hung-yi-Lee/" rel="tag">Hung-yi Lee</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/NLP/" rel="tag">NLP</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/deep-learning/" rel="tag">deep learning</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/python/" rel="tag">python</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-DLHLP-2020-1" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2023/02/01/DLHLP-2020-1/" class="article-date">
  <time datetime="2023-02-01T14:55:31.000Z" itemprop="datePublished">2023-02-01</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/02/01/DLHLP-2020-1/">DLHLP 2020 (1)</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>接下來的內容為李宏毅老師的DLHLP(Deep Learning and Human Language Processing)課程。<br>當中包含許多機器學習與深度學習的內容，我將其中有關於文字部分的NLP(Natural laguage processing)內容抓出來，並且做一個小整理。<br><a href="https://frafishen.github.io/2023/02/02/DLHLP-2020-2/">下一篇</a></p>
<h2 id="DLHLP-2020-Overview-of-NLP-Tasks"><a href="#DLHLP-2020-Overview-of-NLP-Tasks" class="headerlink" title="[DLHLP 2020] Overview of NLP Tasks"></a><a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=tFBrqPPxWzE">[DLHLP 2020] Overview of NLP Tasks</a></h2><ul>
<li>基本上現在大家直接說NLP的話，都是在指說處理文字的部分，也就是<ul>
<li>sequence2sequence</li>
<li>sequence2class</li>
</ul>
</li>
<li>sequence2class主要會分成兩種類型<ul>
<li>sequence中每一個token都會輸出一個對應的class</li>
<li>一個sequence只會輸出一個class</li>
</ul>
</li>
<li>sequence2sequence有些會有copy mechanism，就是會直接把輸入的內容再直接貼上去。中間會經歷encoder將內容轉換成可以用來embedding的token，attention layer的機制會讓這些embedding的東西可以在訓練學習的過程中，去不斷地更改權重。</li>
<li>attention layer就是就是用來訓練參數的層(超參數是一開始就訂好的那些，比如說epho要多少次之類的)，在Bert出來之前self-attention的機制會被稱作是，self-matching或是self-boosting之類的。</li>
<li>假如說有不只一個sequence需要輸入的話，<ul>
<li>將兩個sequences中間加入一個&lt;SEP&gt;，再丟入model訓練</li>
<li>將兩個sequence分別丟入model，然後再利用attention的機制將他們integrate在一起</li>
</ul>
</li>
<li>NLP的主要發展方向為下圖<br><img src="https://i.imgur.com/cSyNFK8.png"><ul>
<li>word segmentation =&gt; 分詞<ul>
<li>Input: sequence</li>
<li>Output: class for each token</li>
</ul>
</li>
<li>POS(Partof-Speech) Taggging =&gt; 幫token貼標籤</li>
<li>parsing =&gt; 將POS tagging過的資料，進行句法分析，可用於downstream tasks<ul>
<li>constituency parsing</li>
<li>dependency parsing</li>
</ul>
</li>
<li>coreference resolution =&gt; 指代消解，將同樣的entity(eg. 代名詞、代稱)進行cluster分堆</li>
<li>summarization =&gt; 摘要<ul>
<li>extractive summarization =&gt; 擷取式摘要。model中，每個token會是一個sentence，輸出的產物，會是分數比較高的token。<ul>
<li>Input: sequence</li>
<li>Output: class for each token</li>
</ul>
</li>
<li>abstractive summarization =&gt; 自己寫一段摘要。摘要的內容依舊會是來自原本的輸入的內容，利用到前面提到的copy mechanism，但內容會自己重新排列組合過。<ul>
<li>Input: sequence</li>
<li>Output: sequence</li>
</ul>
</li>
</ul>
</li>
<li>machine translation<ul>
<li>Input: sequence</li>
<li>Output: sequence</li>
<li>類別<ul>
<li>文字對文字</li>
<li>語音對文字</li>
<li>語音對語音</li>
</ul>
</li>
</ul>
</li>
<li>Grammar Error Correction<ul>
<li>Input: sequence</li>
<li>Output: sequence</li>
</ul>
</li>
<li>Sentiment Classification<ul>
<li>Input: sequence</li>
<li>Output: class</li>
</ul>
</li>
<li>Stance Detection =&gt; 立場分析<ul>
<li>Input: two sequences</li>
<li>Output: a class</li>
</ul>
</li>
<li>Veracity Prediction<ul>
<li>Input: several sequences =&gt; 多個資料來源</li>
<li>Output: a class =&gt; true/false</li>
</ul>
</li>
<li>NLI(Natural Language Inference)<ul>
<li>Input: two sequences =&gt; 輸入一張照片，和一段對於照片的敘述</li>
<li>Output: a class =&gt;contradiction/ entailment/ nutral</li>
</ul>
</li>
<li>search engine<ul>
<li>Input: two sequences =&gt; 搜尋關鍵字，匹配的網頁內容</li>
<li>Output: a class =&gt; 有沒有相關</li>
</ul>
</li>
<li>下圖是兩個骨董QA model的模型<br><img src="https://i.imgur.com/btUwVJp.png"><ul>
<li>最簡單來說，其實就是做閱讀測驗，輸入會有question和knowledge source where comes from search engine and the content has already been filtered out the irrelevant documents，然後進入model最後輸出答案</li>
<li>extractive QA: 一樣輸入question and documents，輸出頭的位置和尾的位子，所以基本上輸出稅copy輸入的內容。<ul>
<li>Input: several sequences</li>
<li>Output: sequence</li>
</ul>
</li>
</ul>
</li>
<li>dialogue<ul>
<li>chatting<ul>
<li>將bg，像是personality, empathy, and some background knowledge拿來訓練model</li>
<li>通常輸出的結果會看起來很無俚頭，就是有點幹話的感覺。</li>
</ul>
</li>
<li>task-oriented<ul>
<li>NLG<br><img src="https://i.imgur.com/7SoORKn.png"></li>
<li>policy &amp; state tracker<br><img src="https://i.imgur.com/kQSF04O.png"></li>
<li><ul>
<li>NLU(Natural Language Understanding)</li>
</ul>
<ul>
<li>有點像是POS tagging，但是其中的標籤可能會多出一些我們需要的資訊，作為收集填入 -&gt; slot filling</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>Knowledge Extraction<ul>
<li>有點像圖論，node-&gt;extract entity，edge-&gt;extract relation</li>
</ul>
</li>
<li>Name Entity Recognition (NER)<ul>
<li>Input: sequence </li>
<li>Output: class for each token</li>
</ul>
</li>
</ul>
</li>
<li>比較厲害的綜合體<ul>
<li>General Language Understanding Evaluation (GLUE)</li>
<li>super glue</li>
<li>DecaNLP</li>
</ul>
</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://frafishen.github.io/2023/02/01/DLHLP-2020-1/" data-id="cldlsp8yd0000ioc29em3fsw0" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/DLHLP/" rel="tag">DLHLP</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Hung-yi-Lee/" rel="tag">Hung-yi Lee</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/NLP/" rel="tag">NLP</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/deep-learning/" rel="tag">deep learning</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/python/" rel="tag">python</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-Intel-computer" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2022/12/15/Intel-computer/" class="article-date">
  <time datetime="2022-12-14T18:30:20.000Z" itemprop="datePublished">2022-12-15</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2022/12/15/Intel-computer/">Intel Taiwan 校園電腦組裝大賽</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>哈囉各位大大好，因為最近開始跑一些NLP和影像辨識的模型，本來就有想要自己裝電腦的念頭。後來發現Intel有辦了這麼一場裝電腦的比賽，所以就報報看吶，應比賽的要求，需要分享一下菜單。</p>
<p>我也是第一次真的要認真從頭裝電腦，之前都只是局部升級而已。不管有沒有晉級，我應該都會真的去裝它哈哈。</p>
<h2 id="背景說明"><a href="#背景說明" class="headerlink" title="背景說明"></a>背景說明</h2><h4 id="1-就讀學系：資訊管理學系"><a href="#1-就讀學系：資訊管理學系" class="headerlink" title="1. 就讀學系：資訊管理學系"></a>1. 就讀學系：資訊管理學系</h4><h4 id="2-對於電腦的需求"><a href="#2-對於電腦的需求" class="headerlink" title="2. 對於電腦的需求"></a>2. 對於電腦的需求</h4><ul>
<li>目前已經有一部主力的中高階文書筆電，但是以下的要求，在本地跑的情況下，總是讓我在電腦前面等輸出、等運算到天荒地老。</li>
<li>需要訓練/跑簡單的機器學習及深度學習的模型<ul>
<li>資料探勘</li>
<li>NLP</li>
<li>影像識別</li>
</ul>
</li>
<li>需要使用處理影像相關軟體 (Adobe Suite)</li>
</ul>
<h2 id="菜單與原因"><a href="#菜單與原因" class="headerlink" title="菜單與原因"></a>菜單與原因</h2><ul>
<li><em>CPU：Intel Core i5-13600K（NT$10,990）</em><ul>
<li>其14核20執行緒可以在影片剪輯以及檔案編碼上提供強大的多核性能</li>
<li>最新的Intel 7工藝可以讓這顆CPU在更低的電壓下達到更高的頻率</li>
</ul>
</li>
<li><em>主機板：華碩 TUF GAMING Z690-PLUS WIFI D4（$6990）</em><ul>
<li>8+4pin供電讓主板超頻能力更強</li>
<li>具有藍牙、WiFi6無線網路與2.5Gbps的乙太網</li>
</ul>
</li>
<li><em>記憶體：金士頓 8GB DDR4-3200 FURY Beast(KF432C16BB/8)X2（$1398）</em><ul>
<li>記憶體可以根據使用情況自行再擴充</li>
<li>頻率達3200，CL16</li>
<li>帶有散熱片，可以讓它的超頻潛力更強</li>
</ul>
</li>
<li><em>存儲：KLEVV CRAS C710 512G（$950）</em><ul>
<li>其最高讀2050MB/S,最高寫1650MB/S的高速，在影片剪輯上會有顯著的幫助</li>
<li>五年保修</li>
</ul>
</li>
<li><em>散熱器：利民 Silver Soul 135（NT$1,590）</em><ul>
<li>6組熱管雙塔設計給它帶來220W的解熱能力</li>
<li>採用全電鍍回流焊工藝，壽命更長的同時性能更好</li>
</ul>
</li>
<li><em>GPU: 微星 RTX2060 VENTUS 12G OC（$9990）</em><ul>
<li>12G的大顯存可以在深度學習時避免因顯存不夠而導致報錯</li>
<li>雙風扇的設計讓其散熱性能更強</li>
</ul>
</li>
<li><em>機殼：視博通 影武戰士 PRO（$1290）</em></li>
<li><em>電源供應器：華碩 TUF GAMING 650W 銅牌（$2490）</em><ul>
<li>CPU超頻後整機功耗可達420W以上，考慮以後可能會更換硬件升級650W的電源</li>
</ul>
</li>
<li>總價格：NT$35,588</li>
</ul>
<h2 id="原價屋估價單"><a href="#原價屋估價單" class="headerlink" title="原價屋估價單"></a>原價屋估價單</h2><p><img src="https://i.imgur.com/rFISQH6.png"></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://frafishen.github.io/2022/12/15/Intel-computer/" data-id="clbnzv4yx0000dkc2cak7foqa" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Computer/" rel="tag">Computer</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Intel/" rel="tag">Intel</a></li></ul>

    </footer>
  </div>
  
</article>


  


  <nav id="page-nav">
    
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="page-number" href="/page/3/">3</a><a class="extend next" rel="next" href="/page/2/">下一頁 &amp;raquo;</a>
  </nav>

</section>
        
          <aside id="sidebar">
  
    

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">標籤</h3>
    <div class="widget">
      <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/Bert/" rel="tag">Bert</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Computer/" rel="tag">Computer</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/DLHLP/" rel="tag">DLHLP</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ELMO/" rel="tag">ELMO</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Git/" rel="tag">Git</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Github-Pages/" rel="tag">Github-Pages</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Hung-yi-Lee/" rel="tag">Hung-yi Lee</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Intel/" rel="tag">Intel</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Kotlin/" rel="tag">Kotlin</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/NLP/" rel="tag">NLP</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Vite/" rel="tag">Vite</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Vue3/" rel="tag">Vue3</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/about/" rel="tag">about</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/algorithm/" rel="tag">algorithm</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/app/" rel="tag">app</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/c/" rel="tag">c++</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/data-science/" rel="tag">data-science</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/deep-learning/" rel="tag">deep learning</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/front-end/" rel="tag">front_end</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/general-education/" rel="tag">general education</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/leetcode/" rel="tag">leetcode</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/machine-learning/" rel="tag">machine learning</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/opencv/" rel="tag">opencv</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/paper/" rel="tag">paper</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/programming/" rel="tag">programming</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/python/" rel="tag">python</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/virtualenv/" rel="tag">virtualenv</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/website/" rel="tag">website</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">標籤雲</h3>
    <div class="widget tagcloud">
      <a href="/tags/Bert/" style="font-size: 10px;">Bert</a> <a href="/tags/Computer/" style="font-size: 10px;">Computer</a> <a href="/tags/DLHLP/" style="font-size: 16px;">DLHLP</a> <a href="/tags/ELMO/" style="font-size: 10px;">ELMO</a> <a href="/tags/Git/" style="font-size: 10px;">Git</a> <a href="/tags/Github-Pages/" style="font-size: 10px;">Github-Pages</a> <a href="/tags/Hung-yi-Lee/" style="font-size: 16px;">Hung-yi Lee</a> <a href="/tags/Intel/" style="font-size: 10px;">Intel</a> <a href="/tags/Kotlin/" style="font-size: 14px;">Kotlin</a> <a href="/tags/NLP/" style="font-size: 20px;">NLP</a> <a href="/tags/Vite/" style="font-size: 10px;">Vite</a> <a href="/tags/Vue3/" style="font-size: 12px;">Vue3</a> <a href="/tags/about/" style="font-size: 12px;">about</a> <a href="/tags/algorithm/" style="font-size: 10px;">algorithm</a> <a href="/tags/app/" style="font-size: 10px;">app</a> <a href="/tags/c/" style="font-size: 12px;">c++</a> <a href="/tags/data-science/" style="font-size: 10px;">data-science</a> <a href="/tags/deep-learning/" style="font-size: 18px;">deep learning</a> <a href="/tags/front-end/" style="font-size: 10px;">front_end</a> <a href="/tags/general-education/" style="font-size: 12px;">general education</a> <a href="/tags/leetcode/" style="font-size: 10px;">leetcode</a> <a href="/tags/machine-learning/" style="font-size: 12px;">machine learning</a> <a href="/tags/opencv/" style="font-size: 10px;">opencv</a> <a href="/tags/paper/" style="font-size: 10px;">paper</a> <a href="/tags/programming/" style="font-size: 12px;">programming</a> <a href="/tags/python/" style="font-size: 20px;">python</a> <a href="/tags/virtualenv/" style="font-size: 10px;">virtualenv</a> <a href="/tags/website/" style="font-size: 12px;">website</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">彙整</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/02/">二月 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/12/">十二月 2022</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/10/">十月 2022</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/09/">九月 2022</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/08/">八月 2022</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/07/">七月 2022</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/06/">六月 2022</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">最新文章</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2023/02/18/build-vir-env/">Build a Virtual Environment for Development Purpose</a>
          </li>
        
          <li>
            <a href="/2023/02/08/DLHLP/">DLHLP-2020</a>
          </li>
        
          <li>
            <a href="/2023/02/07/DLHLP-2020-5/">DLHLP 2020 (5)</a>
          </li>
        
          <li>
            <a href="/2023/02/06/DLHLP-2020-4/">DLHLP 2020 (4)</a>
          </li>
        
          <li>
            <a href="/2023/02/05/DLHLP-2020-3/">DLHLP 2020 (3)</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2023 Jenny Shen<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>




<script src="/js/script.js"></script>




  </div>
</body>
</html>